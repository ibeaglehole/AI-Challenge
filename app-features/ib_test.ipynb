{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook experimenting with models available online"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have created a local file, **api_keys.py**, in the same directory as the notebook which contains variables with the api keys associated with the different services. You will need to do the same for this code to work. This will require creating accounts with [AssemblyAI](https://www.assemblyai.com) and [OpenAI](https://openai.com) to get your individual api keys.\n",
    "\n",
    "Example for the **api_keys.py** file:\n",
    "\n",
    "aai_api_key = {YOUR_ASSEMBLYAI_API_KEY}\n",
    "\n",
    "You will also need install these packages:\n",
    "- assemblyai\n",
    "- langchain_community\n",
    "- langchain_openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import assemblyai as aai\n",
    "from langchain_community.document_loaders import AssemblyAIAudioTranscriptLoader\n",
    "from langchain_openai import OpenAI\n",
    "from api_keys import aai_api_key, openai_api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test journal stored under the filename \"test_journal.m4a\"\n",
    "audio_file = \"test_journal.m4a\"\n",
    "\n",
    "# configuration for the model performing the transcription\n",
    "config = aai.TranscriptionConfig(\n",
    "    sentiment_analysis = True,\n",
    "    summarization=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = AssemblyAIAudioTranscriptLoader(file_path=audio_file,\n",
    "                                         api_key=aai_api_key,\n",
    "                                         config=config)\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# docs[0].page_content\n",
    "# docs[0].metadata['audio_duration']\n",
    "# docs[0].metadata['confidence']\n",
    "# docs[0].metadata['words'][0]\n",
    "# docs[0].metadata['summary']\n",
    "# docs[0].metadata['sentiment_analysis_results'][7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 3 3\n"
     ]
    }
   ],
   "source": [
    "pos, neu, neg = 0, 0, 0\n",
    "\n",
    "# docs[0].metadata['sentiment_analysis']\n",
    "for i in docs[0].metadata['sentiment_analysis_results']:\n",
    "    sentiment = i['sentiment'].value\n",
    "    if sentiment == \"POSITIVE\":\n",
    "        pos += 1\n",
    "    elif sentiment == \"NEUTRAL\":\n",
    "        neu += 1\n",
    "    elif sentiment == \"NEGATIVE\":\n",
    "        neg += 1\n",
    "\n",
    "print(pos, neu, neg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying through AssemblyAI directly, rather than AssemblyAI through LangChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "aai.settings.api_key = aai_api_key\n",
    "\n",
    "transcriber = aai.Transcriber()\n",
    "transcript = transcriber.transcribe(audio_file, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transcript.text\n",
    "# transcript.words\n",
    "# transcript.sentiment_analysis\n",
    "# transcript.summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use lemur llm from AssemblyAI to summarise the transcript into emotions - have to pay to use api\n",
    "result = transcript.lemur.task(\n",
    "    prompt=\"Summarise the feelings in this transcript into a few key words\",\n",
    "    temperature=0.5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# possible to remove all data relating to request - good for controlling data\n",
    "aai.Lemur.purge_request_data(result.request_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OpenAI below - need to pay to use api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(api_key=openai_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt=\"Summarise the feelings in this transcript into a few key words\"\n",
    "\n",
    "llm.invoke(\n",
    "    input = f\"{prompt} : {docs[0].page_content}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Proof of concepts completed so far:\n",
    "- Speech-to-text conversion (transcription)\n",
    "- Sentiment analsis\n",
    "- Summary (kind of - not sure how useful the summary from AssemblyAI is)\n",
    "\n",
    "Next:\n",
    "- Integrate transcription with LLM to generate keywords for a summary / determine topics discussed / extract some emotion or feeling\n",
    "- Analysis of audio (pitch, tone, loudness etc.)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
