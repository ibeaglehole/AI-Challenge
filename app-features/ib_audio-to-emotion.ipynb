{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifying Audio to Emotion using the RAVDESS dataset\n",
    "### [Medium Article](https://medium.com/@tushar.gupta_47854/speech-emotion-detection-74337966cf2) | [GitHub](https://github.com/RoccoJay/Audio_to_Emotion)\n",
    "###### Livingstone SR, Russo FA (2018) The Ryerson Audio-Visual Database of Emotional Speech and Song (RAVDESS): A dynamic, multimodal set of facial and vocal expressions in North American English. PLoS ONE 13(5): e0196391. https://doi.org/10.1371/journal.pone.0196391."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import glob \n",
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import joblib\n",
    "from tqdm import tqdm\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1961, 491)\n",
      "Features extracted: 180\n",
      "0.7535641547861507\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = pd.read_csv('a2e-data/X_train.csv'), pd.read_csv('a2e-data/X_test.csv'), pd.read_csv('a2e-data/y_train.csv'), pd.read_csv('a2e-data/y_test.csv')\n",
    "\n",
    "print((X_train.shape[0], X_test.shape[0]))\n",
    "\n",
    "print(f'Features extracted: {X_train.shape[1]}')\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "mlp_params = {'activation': 'relu', \n",
    "              'solver': 'lbfgs', \n",
    "              'hidden_layer_sizes': 1283, \n",
    "              'alpha': 0.3849485717707319, \n",
    "              'batch_size': 163, \n",
    "              'learning_rate': 'constant',\n",
    "              'max_iter':1000}\n",
    "\n",
    "model = MLPClassifier(**mlp_params)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "def print_confusion_matrix(confusion_matrix, class_names, figsize = (10,7), fontsize=14, model='clf', save=True):\n",
    "    \"\"\"Prints a confusion matrix, as returned by sklearn.metrics.confusion_matrix, as a seaborn heatmap. \n",
    "    Saves confusion matrix file to jpg file.\"\"\"\n",
    "    df_cm = pd.DataFrame(\n",
    "        confusion_matrix, index=class_names, columns=class_names, \n",
    "    )\n",
    "    fig, ax = plt.subplots(1, 1, figsize=figsize)\n",
    "    try:\n",
    "        heatmap = sns.heatmap(df_cm, annot=True, ax=ax, fmt=\"d\", cmap=plt.cm.Oranges)\n",
    "    except ValueError:\n",
    "        raise ValueError(\"Confusion matrix values must be integers.\")\n",
    "        \n",
    "    heatmap.yaxis.set_ticklabels(heatmap.yaxis.get_ticklabels(), rotation=0, ha='right', fontsize=fontsize)\n",
    "    heatmap.xaxis.set_ticklabels(heatmap.xaxis.get_ticklabels(), rotation=45, ha='right', fontsize=fontsize)\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.tight_layout()\n",
    "    # fix for mpl bug that cuts off top/bottom of seaborn viz\n",
    "    b, t = plt.ylim() \n",
    "    b += 0.5 \n",
    "    t -= 0.5 \n",
    "    plt.ylim(b, t) \n",
    "    if save == True:\n",
    "        plt.savefig('tuned_' + \"MLP_Classifier\" + '_confusion_matrix.jpg')\n",
    "    plt.show()\n",
    "\n",
    "def models(clf_model=model, X_train=X_train, X_test=X_test, y_train=y_train, y_test=y_test, y_pred = y_pred, save=False, print_stat=False, inc_train=False, cv=False):\n",
    "    \"\"\"Trains models and outputs score metrics. Takes an identifier, list of models, and split dataset as inputs and has options for saving model, \n",
    "    printing confusion matrix and classification report and getting cross-validated 5 fold accuracy.\"\"\"\n",
    "    if print_stat == True:\n",
    "        clf_report = pd.DataFrame(classification_report(y_test,y_pred, output_dict=True)).T\n",
    "        clf_report.to_csv('tuned_MLP_Classifier_classification_report.csv')\n",
    "        print(\"MLP_Classifier\")\n",
    "        print('\\nTest Stats\\n', classification_report(y_test,y_pred))\n",
    "        print_confusion_matrix(confusion_matrix(y_test, y_pred), unique_labels(y_test, y_pred), model=clf_model)\n",
    "        if inc_train == True:\n",
    "            print(\"MLP_Classifier\")\n",
    "            print('\\nTrain Stats\\n', classification_report(y_train,clf_model.predict(X_train)))\n",
    "            print_confusion_matrix(confusion_matrix(y_train, clf_model.predict(X_train)), unique_labels(y_test, y_pred), model=clf_model)\n",
    "    if cv == True:\n",
    "        print(\"MLP_Classifier\" + ' CV Accuracy:',  \n",
    "              np.mean(cross_val_score(clf_model, X_train, y_train, cv=5, scoring='accuracy')))\n",
    "    if save == True:\n",
    "        return clf_model\n",
    "    \n",
    "a = models()\n",
    "\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_feature(file_name):\n",
    "    \"\"\"Function Extracts Features from WAV file\"\"\"\n",
    "    X, sample_rate = librosa.load(file_name)\n",
    "    stft=np.abs(librosa.stft(X))\n",
    "    result=np.array([])\n",
    "    mfccs=np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=40).T,axis=0)\n",
    "    result=np.hstack((result, mfccs))\n",
    "    chroma=np.mean(librosa.feature.chroma_stft(S=stft, sr=sample_rate).T,axis=0)\n",
    "    result=np.hstack((result, chroma))\n",
    "    mel=np.mean(librosa.feature.melspectrogram(y=X, sr=sample_rate).T,axis=0)\n",
    "    result=np.hstack((result, mel))\n",
    "    return result\n",
    "\n",
    "emotions={\n",
    "  '01':'neutral',\n",
    "  '02':'calm',\n",
    "  '03':'happy',\n",
    "  '04':'sad',\n",
    "  '05':'angry',\n",
    "  '06':'fearful',\n",
    "  '07':'disgust',\n",
    "  '08':'surprised'\n",
    "}\n",
    "\n",
    "def gender(g):\n",
    "    \"\"\"Returns Gender Label\"\"\"\n",
    "    if int(g[0:2]) % 2 == 0:\n",
    "        return 'female'\n",
    "    else:\n",
    "        return 'male'\n",
    "    \n",
    "def load_data(test_size=0.2):\n",
    "    \"\"\"Loads Data from directory containing WAV files.\"\"\"\n",
    "    x,y=[],[]\n",
    "    for file in tqdm(glob.glob(\"*.m4a\")):\n",
    "        file_name=os.path.basename(file)\n",
    "        emotion=emotions[file_name.split(\"-\")[2]] + '_' + gender(file_name.split(\"-\")[-1])\n",
    "        feature=extract_feature(file)\n",
    "        x.append(feature)\n",
    "        y.append(emotion)\n",
    "    return train_test_split(np.array(x), y, test_size=test_size, random_state=9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib, librosa, numpy as np, pandas as pd, warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "class emotion_classifier():\n",
    "    \n",
    "    def __init__(self, audio_fp, model_fp):\n",
    "        self.file_name = audio_fp\n",
    "        self.model = joblib.load(model_fp)\n",
    "        self.possible_emotions = [emotion.split('_')[0] for emotion in self.model.classes_][::2]\n",
    "\n",
    "    def extract_features(self):\n",
    "        \"\"\"Function Extracts Features from WAV file\"\"\"\n",
    "        X, sample_rate = librosa.load(self.file_name)\n",
    "        stft=np.abs(librosa.stft(X))\n",
    "        result=np.array([])\n",
    "        mfccs=np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=40).T,axis=0)\n",
    "        result=np.hstack((result, mfccs))\n",
    "        chroma=np.mean(librosa.feature.chroma_stft(S=stft, sr=sample_rate).T,axis=0)\n",
    "        result=np.hstack((result, chroma))\n",
    "        mel=np.mean(librosa.feature.melspectrogram(y=X, sr=sample_rate).T,axis=0)\n",
    "        result=np.hstack((result, mel))\n",
    "        return result\n",
    "    \n",
    "    def extract_prob_emotions(self):\n",
    "        features = self.extract_features()\n",
    "        prob_emotions = pd.Series(self.model.predict_proba(features.reshape(1, -1))[0],\n",
    "                                  index=self.model.classes_).sort_values(ascending=False)\n",
    "        return prob_emotions\n",
    "\n",
    "    def top3emotions(self):\n",
    "        prob_emotions = self.extract_prob_emotions()\n",
    "        top3 = []\n",
    "        for entry in prob_emotions.index:\n",
    "            emotion = entry.split('_')[0]\n",
    "            if emotion not in top3 and len(top3) < 3:\n",
    "                top3.append(emotion)\n",
    "                \n",
    "        return top3\n",
    "    \n",
    "    def weighted_emotions(self):\n",
    "        prob_emotions = self.extract_prob_emotions()\n",
    "        total_prob_emotions = {}\n",
    "        \n",
    "        for index, prob in prob_emotions.items():\n",
    "            emotion = index.split('_')[0]\n",
    "            if emotion in total_prob_emotions:\n",
    "                total_prob_emotions[emotion] += prob\n",
    "            else:\n",
    "                total_prob_emotions[emotion] = prob\n",
    "\n",
    "        return total_prob_emotions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = emotion_classifier('test_journal.m4a', 'models/mlp_emotion_classifier.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sad', 'calm', 'neutral']\n",
      "{'sad': 1.0, 'calm': 6.250119897169803e-61, 'neutral': 1.6360460307621584e-202, 'angry': 0.0, 'disgust': 0.0, 'fearful': 0.0, 'happy': 0.0, 'surprised': 0.0}\n"
     ]
    }
   ],
   "source": [
    "print(test.top3emotions())\n",
    "print(test.weighted_emotions())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write Data to csv Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for file, name in zip([X_train, X_test, y_train, y_test],['a2e-data/X_train.csv', 'a2e-dataX_test.csv', 'a2e-datay_train.csv', 'a2e-datay_test.csv']):\n",
    "#     pd.DataFrame(file).to_csv(name, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
